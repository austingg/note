2016-03-17
===============
### Learn Lua in 15 Minutes

#### Comment
* -- Two dashes start a one-line comment
* Adding two ['s and ]'s makes it a multi-line comment.

#### Variable and flow control
* All numbers are doubles
* s = 'waternate' Immutable strings like Python "double-quotes are also fine"
* t = nil   --Undefines t; Lua has garbage collection.
* Blocks are denoted with keywords like do/end. While loop
* If clause. If then else
* Only nil and false are falsy; 0 and '' are true!
* and or are short-circuited.
* i = 1, 100  range includes both ends.
* varibles are default global. use local for local variable.

#### Functions
* x, y, z = 1, 2, 3, 4. Returns, func calls, and assignments all work with lists that may be mismatched in length. Unmatches receivers are nil; unmatched senders are discarded.
* calls with one string param don't need parents: print 'hello'


#### Tables
* Lua's only compound data structure; they are associative arrays.
* Using tables as dictionaries / maps
* for key, val in pairs(u) do print (key, val)
* Using tables as lists/arrays v = {'value', 'value2', 1.21, 'gigawatts'}
* #v is the size of v for lists 
* Metatables and metamethods. setmetatable

#### Class-like tables and inheritance
* classse aren't built in; there are different ways to make them using tables and metatables.

Dog = {}

function Dog:new()
    newObj = {sound = 'woof'}
    self.__index = self
    return setmetatable(newObj, self)
end

function Dog:makeSound()
    print('I say' .. self.sound)
end

mrDog = Dog:new()
mrDog:makeSound()


* Dog asts like a class; it's really a table.
* function tablename:fn(...) is the same as function tablename.fn(self, ..)


#### Modules
mod.lua
local M = {}
....
...
return M

* Another file can use mod.lua's functionality.
local mode = require('mod')
* require is the standard way to include modules.
* require's return values are cached so a file is run at most once, even when  many times.
* dofile('mod.lua') dofile is like require without caching


### Associative array
In computer science, an associative array, map, symbol table, or dictionary is an abstract data type composed of a collection of (key, value) pairs, such that each possible key appears just once in the collection.
* The dictionary problem is a classic computer science problem: the task of designing a data structure that maintains a set of data during 'search' 'delete' and 'insert' operations.  A standard solution to the dictionary problemis a hash table. 
* Many programming languages include associative array as primitive data types.
* Implementation
    1. dictionaries with very small numbers of bindings, it may make sense to implement the dictinary using an association list, a linked list of bingding. linear in the total number of bindings.
    2. Another very simple implementation technique, usable when the keys are restricted to narrow range of integers, is direct addressing into an array.
    3. The most frequently used general purpose implementation of associative array is with hash table.
    4. Another common approach is to implment an associative array with (self-banlancing) red-black tree.



### Identity Mappings in Deep Residual Networks

* Key points:   **Identity** Mapping**s**
   1. keep skip connection clean
   2. pre-activations(no other operation after element-wise additive), BN and relu only for residual path.
* Deep residual networks have emerged as a family of extremely deep architectures showing compelling accuracy and nice convergence behaviors.
* In this paper, we analyze the propagation formulations behind the residual building blocks, which suggest that the forward and backward signals can be directly propagated from the one block to any other block, when using identity mappings as the skip connections and after-addition activation.
* A series of ablation experiments support the importance of these identity mappings.
* This motivates us to propose a new residual unit, which further makes training easy and imporves generalizatin.
* We report improved results using a 1001-layer ResNet on CIFAR-10/100, and 200-layer ResNet on ImageNet.


These experiments suggest that keeping a "clean" information path
