2016-03-18  
===============
### DeepCompress series (3 papers)
1. DeepCompress
2. DeepCompress
3. EIE: efficient inference engine on compressed Deep Neural Network



### MatchNet: Unifying Feature and Metric Learning for Patch-Based Matching (CVPR-2015) 
[code](https://github.com/hanxf/matchnet)


### songhan/SqueezeNet-Generator
[code](https://github.com/songhan/SqueezeNet-Generator)


### cutorch Topk
1. note that top-k or sort for the outermost dimension or any dimension which is non-contiguous will always be slow.
2. y, i = torch.topk(x, k, dim, dir) add a sorting direction that has the same sense as torch.sort; false returns the k smallerst elements in the slice, true, returns the k largest elements in the slice.





### Torch 
* SpatialBatchNormalization: mean/std normalization over the mini-batch inputs and pixels, with an optional affine transform that follows a kernel for computeing the weighted average in a neighborhood.
* Spatial Modules: spatial layers expect a 3D Tensor as input. The first dimension is the number of features, the last two dimensions are spatial. These are commonly used for processing images.
* SpatialConvolution: Applies a 2D convolution over an input image composed of several input planes. The input tensor in forward(input) is expected to be a 3D tensor(nInputPlane x height x width)
* Tensor is a potentially multi-dimensional matrix. The number of dimension is unlimited that can be created using LongStorage with more dimensions. The tensor might not be contiguous. One could say that a Tensor is a particular way of viewing a Storage: a storage only represents a chunk of memory, while the Tensor interprets this chunk of memory as having dimensions.
* torch.setdefaulttensortype('torch.FloatTensor') -> For convenience, an alias torch.Tensor is provided, which allows the user to write type-independet scripts, which can then ran after choosing the desired Tensor type with a call like.
* If you really need to copy a Tensor, you can use the copy() method, or the convenience method y = x:clone()
* torch.Tensor(tensor) : the new Tensor is now going to "view" the same storage as given tensor.
* configuous: if the given tensor contents are contiguous in memory, returns the exact same Tensor, otherwise(not contiguous in memory), returns a clone.
* type()  if type is a string describing a Tensor type, different from the type name of the given Tensor, returns a new Tensor of the specified type, whose contents corresponds to the contents of the original Tensor, casted to the given type(memory copy occurs, with possible loss of precision) for convinient float(), double(), long()
* nDimension() dim(), size() isContiguous() isSameSizeAs(tensor) nElement()
* Querying elements: retrieve with [index] operator.
* resizeAs, resize()
* Extracting Sub-tensors: returns a tensor which is a sub-tensor of the given tensor, with the same Storage.  narrow(dim, index, size), sub(dim1s, dim1e, dime2s, dim2e)  [{dim1, dim2}] [{{dim1s, dim2e}, (dim2s, dim2e}}]
* 
