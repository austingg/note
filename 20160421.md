2016-04-21
========
# Recognizing Image Style
1. The style of an image plays a significant role in how it is viewed, but style has received little attention in computer vision resarch. 
2. We use the learned classifiers to extend traditional tag-based image search to consider stylistic constraints, and demonstrate cross-dataset understanding of style.
3. Distince visual styles are apparent in art, cinematorgraphy, advertising, and have becom extremely popular in amateur photography, with apps like Instagram leading the way.
4. Although is it very recognizable to human observers, visual style is a difficult concept to rigorously define.
5. We define serveral different types of image style, and gather a new, large-scale dataset of photographs annotated with style labels.
6. Most previous work in aesthetic sytle analysis has used hand-tuned features, such as color histograms. We find that deep convolutional neural network (CNN) features perform best for the task. This is surprising for serveral reasons: these features were trained on object class categories (ImageNet), and many styles appears to be primiarily about color choices, yet the CNN features handily beat color histogram features. This leads to on conclusion of our work: mid-level features derived from object datasets are generic for style recognition, and superior to hand-tuned features.
7. A few previos works have focused directly on image composition, particularly on the high-level attributes of beauty, interestingness, and memorability.
8. Building an effective model of photographics style requires annotated trainning data. We would like to study a broader range of styles, including different types of styles ranging from genres, compositional styles, and moods. Moreever, large datasets are desirable in order to obtain effective results, and so we would like to obtain data from online communities, such as Flickr.
9. The derived labels are considered clean in positive examples, but may be noisy in the negative examples, in the same way also be Romantic, for which it is not labeld. We consider this an unfortunate but acceptable reality of working with a large-scale dataset. 

Mainly use Generic of Deep feature to train new classifier. Maybe End-to-End trainning more accurate

# Finetune Flickr style
1. The Flickr-sourced images of the Style dataset are visually very similar to the ImageNet dataset, on which the bvlc_reference_caffenet was trained. Since that model works well for object category classification, we'd like to use this architecture for our style classifier.We also only have 80,000 images to trian on, so we'd like to start with the parameters learned on the 1,000,000 ImageNet images, and fine-tune as needed. If we provide the weights argument to the caffe train command, the pretrained weights will be loaded into our model, matching layers by name.

Because we are predicting 20 classes instead of a 1000, we do need to change the last layer in the model. Therefor, we change the name of the last layer from fc8 to fc8_flickr in our prototxt. Since there is no layer named that in the bvlc_reference_caffenet, that layer will begin training with random weights.

We will also decrease the overall learning rate base_lr in the solver prototxt, but boost the lr_mult on the newly introduced layer. The idea is to have the rest of the model change very slowly with new data, but let the new layer learn fast. Additionally, we set the stepsize in the solver to a lower value than if we were training from scratch, since we've virtually far along in training the therefore want to learning rate to go down faster. Note that we could also entirely prevent fine-tuning of all layers other than fc9_flickr by setting theire lr_mult to 0.


# Useful Datasets:
1. AVA: A large-Scale Dataset for Aesthetic Visual Analysis. CVPR 2012
2. Wikipaintings. painting style.


# ToDo List
1. Deep3D model test
2. Ristretto
3. Deep Visual network