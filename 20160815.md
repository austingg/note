2016-08-15
==========
# Texture Net news
1. So probably the trick is finding style images that produce good results, rather than expecting the results to automatically copy the original style as such.
2. Also, I found the display very helpful. Testing different style images, one can usually see quite soon if it will not work at all. If it looks promising, then letting it run further seems to add color quality, up to some point.
3. (myself) maybe a mixture of training dataset will more robust. ImageNet + COCO + Place


# local feature
1. OpenCV's version of SIFT is better optimizated than the version that authors of FREAK use.
2. The most power fo binary descriptors doesn't come from their computational time. Instead the biggest advantage comes from their binary nature. Consequently,
    * they are typically very small resulting in a small memory footprint 
    * they are typically very fast to match (Hamming distance). 
    * The computation times correspond to the descritption and matching of all keypoints. not only the computation of the descriptors but also the matching process is involved.
3. SURF is patened, as is SIFT. ORB and BRIEF are not patented, but their features are not scale-invairant, seriously limiting their usefulness in complex scenarios.
4. FREAK, author claims to have better results than BRISK and ORB. is supposed to be the fastest scale and rotation invariant descriptor extractor, it is open source and you can use it easily as it is implemented in OpenCV. You need a binary matcher that uses the Hamming Distance.

# orb and Arm [http://www.uncannyvision.com/orb-for-real-time-tracking-on-an-arm-processor-2/] 
1. Feature detection and matching is at the heart of several computer vision algorithms. In particular it is used for object recognition, structure from motion, image stitching etc. SIFT and SURF are the 2 popular algorithms in this space.
2. ORB was proposed as an alternative to these 2 algorithms. The original paper(ORB: An efficient alternative to SIFT or SURF). ORB is rotation invariant, but only partially scale invariant. 
3. ORB feature descriptor and matching being significantly faster than SIFT and SURF, is not fast enough to meet real-time requirement for tracking on Cortex A9. 

# Arm Neon
1. iOS Accelerate Framework very powerful.
2. vectorise implementation
3. SIMD

# Android OpenMP 
1. NDK r10

# TODO
1. Texture Net extend: 
    a. retrain
    b. gpu idx


# New papers
1. Factorize Convolutional layers: 
    * 3 times speed up
    * already available in TensorFlow.
    * google ICLR 2014 invited talk
    
tf.nn.separable_conv2d() implements the so-called 'separable convolution' descriped on slide and onward of this talk.

The idea is that instead of convolving jointly across all channels of an image, you run a spearate 2D convolution on each channel with a depth of channel_multiplier. The in_channels * channel_multiplier intemediate channels get concatenated together, and mapped to output_channels using a 1x1 convolution.

It's often an effective way to reduce the parametric complexity of early convolutions in a convnet, 
and can materially speed up training. channel_multiplier controls that complexit, and would typically be 4 or 8 for a RGB input. For a grayscale input, using it make litte sense. [answered by the 'separate convolution neural network']
2. Intel Python very promising

