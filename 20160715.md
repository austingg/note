2016-07-18
==========
# About Prisma
1. By using a combination of neural networks and artificial intelligence, the end results are results are a real sight to behold. It doesn't just put a filter over your image, it actually scans the data to apply the style in an impressive way.
2. It's extremely additive to keep playing with different filters, and apply them to pictures.
3. The hugely popular app is reinventing the way that technology can transform images by recreatinig a photo from scrath, rather than overlaying a filter.
4. Prismaï¼Œis reinventing the concept of filtering photos with technology.
5. While the concept of adding filters to photos has been around for years, the Prisma is unique in the way that it relies on a combination of neural networks and artificial intelligence to remark the image.
6. It appears that the algorithm behind the app was originally published back in late 2015, generatin quite a bit of excitment at the time. Now the technology can be carried around with you in your pocket.


# chainer with cuDNN
1. If you want to enable cuDNN, install cuDNN and CUDA before installing Chiner. We recommend you to install cuDNN to CUDA directory.  

# Texture Networks: Feed-forward Synthesis of Textures and Stylized Images
1. In our paper we describe a faster way to generate textures and styleize image. It requires learning a feedforward generator with a loss function proposed by Gatys et.al. 
2. When the model is trained, a texture sample of any size can be generated instantly.
3. This command should train a generator close to what is presented in the paper. It is tricky, the variance in the results is rather high, many things lead to degrading (even optimizing for too long time).
4. We propose here an alternative approach that moves the computational burden to a learning stage.
5. The resulting fully-convolutional networks (that we call texture networks) can generate textures and process images of arbitrary size. Our apporach also represents an interesting showcase of training conceptually-simple feed-forward architectures while using complex and expressive loss functions. We believe that other interesting results can be obtained using this principle.
6. A separate generator network is trained for each texture or style and, once trained, it can synthesize an arbitray number of images of arbitrary size in an efficient, feed-forward manner.
7. A key challenge in training the generator network g is to construct a loss function that can assess automatically the quality of the generated images. A very powerful loss can be derived from pre-trained and fixed descriptor networks using the statistics/
8. While models of this type produce reasonable results, we found that multi-scale architectures result in images with smaller texture loss and better perceptual quality while using fewer parameters and training faster.
9. For this style transfer application, we found beneficial to increased the number of scales from K = 5 to K = 6. 
10. For training, example natural images were extraced at random from the Imagenet ILSVRC 2012 data.
11. The iterative optimization requires about 10 seconds to generate a sample x that has a loss comparable to the output x = g(z) of our generator network. Since an evalutaion of the latter requires ~20ms, we achieve a 500x speed-up, which is sufficent for real-time applications such as video processing. By aoviding backpropagation, our method also uses significantly less memory 170M to generate 256x256 sample, vs 1100MB

### GitHub Code
1. You may decrease batch_size, imgae_size, noise_depth if the model do not fit your GPU memory
2. pyramid2 is much more memory efficient than pyramid, more, you can decrease the number of filters in there.


3. The pretrained models do not need much memory to sample.

# MxNet GAN End2End neural style
1. However, the architecture above will note guarantee a good result.
2. Training data is 26k images sampled from MIT Place dataset. The code is using MXNet new module API. The pretrained model is trained with 2 epoch.
3. We didn't turn any parameters on these generators. These is A LOT of space to imporve generator's structure and training.
4. Expanding the training dataset will be helpful for various of input. Current is good on buildings, basically it is trained on a subset of Place.
5. Supporting multiple styles. If we assume a artistic style is a function, then support multiple style will be like to make a neural network with many functions.


# Linux build essentials
1. apt-get install -y build-essentials (binutils cpp cp-4.8 g++ gcc and so on)
2. yum groupinstall "Development Tools" (autoconf automake gcc g++ git make )