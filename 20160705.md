2016-07-05
==========
### Hierachical Clustering
1. 
2. Local senstive hashing. One of the the main applications of LSH i sto provide a method for efficient approximate nearest neighbor search algorithms.
    * The problem LSH solves is that finding nearest neighbors is a very expensive, both in time and space when operating in large feature spaces. 
    * The most important applications for LSH is usually in high-dimensional spaces. 
    * Locality senstive hash is a hash function that takes some data point and hashes it into a number, with the added condition that two points that are close by some metric of interest in the original space have hashes that are close to the same value.
    * Clustering is pretty expensive computationally.
    * If a hash has the tendecy to put nearby data into the same bin, then it is a LSH Hash.
    * reduce dimension and binarized the value to use Hamming distance
    
3. Nearest Neighbor, Approximate Nearest Neighbor, ANN
4. opencv: flann
    * LiearIndexParams: a linear, brute-force search
    * KDTreeIndexParams: searched in parallel
    * KMeansIndexParams: hierachical k-means tree
    * CompositeIndexParams : combines the randomized kd-trees and the hierachical k-means tree
    * LshIndexParams: LSH
    * AutotunedIndexParams: automatically tuned to offer the best performance

    
```C++
cv::flann::Index flannIndex(responseDatabase, cv::flann::KDTreeIndexParams(), cv::flann::FLANN_DIST_EUCLIDEAN);
cv::Mat results, dists
int k = 3;
flannIndex.knnSearch(responseQuery, results, dists, k, cv::flann::SearchParams());
```


### Scrapy
#### Why a framework?
1. convetions, common practices
    * easier to share and maintain code among many developers
2. better code reuse
3. intergrated toolset
    * http client, html parsing, url queues
4. simpilfied, consistent operations
    * scrapy crawl ebay -o products.json
5. common foundation for deployments

#### How to make a crawler
1. scrapy startproject PROJECT_NAME
2. Define a Spider class that:
    * Extends BaseSpider
    * has start urls, or a method to generate them
    * has a parse method that generates requests or items
    * has a name
3. Define an item class with contains the field extracted
4. scrapy crawl SPIDER_NAME


### Local sensitive Hash
diffferent distance metric with different LSH function
1. Jaccard distance: IoU, LSH function: minihash
2. Hamming distance: H(V)=element value
3. Cosine distance: H(V)= sign(V*R) R: random vector

similar points are close.