2016-03-25
===============
### www.arxive-sanity.com
1. collect paper
2. recommend paper
3. most recent paper


### New paper
* A guide to convolution arithmetic for deep learning
* Do We Really Need to Collect Millions of Faces for Effective Face Recognition?
* Learning Representations for Automatic Colorization
* Debuging Machine Learning tasks

### Semantic Style Transfer and Turning Two-Bit Doodles into Fine Artwork
1. For most users, however, using upredictable behavior that goes against common intuitions. 
2. This paper introduces a novel concept to augment such generative architectures with semantic annotations, either by mannually authoring pixel lables or using existing solutions for semantic segmentation.
3. For transferring style between two images in particular, results are astonishing-especially with painterly, sketch or abstract styles.
4. However, to achieve good results using neural style transfer in pratice today, users must pay particular attention to the composition and/or style image selection, or risk seeing unpredictable and incorrect patterns.
5. For portraits, facial features can be ruined by incursions of background colors or clothing texture, and for landscapes pieces of vegetation may be found in the sky or other incoherent places.
6. There is certainly a place for this kind of glitch art, but many users become discouraged not being able to get results they want.
7. Through our social media bot that first provided these algorithms as a service, we observe that users have clear expectations how style transfer should occur: most often this matches semantic labels, e.g. hair style and skin tones should transfer respectively regardless of color.
8. Unforutunately, while CNN routinely extract semantic information during classification, such information is pooly exploited by generative algorithms-as evidenced by frequent glitches.
9. The architeture commonly used for image synthesis is augmented with semantic information that can be used during gerneration. 
10. Gram Matrices representation: During thisi operation, all locall information about pixels is lost, and only correlations between the different channels activations remain. When glitches occur, it's most often due to these global statistics being imposed onto the target image regardless of its own statistical distribution, and without any understanding of local pixel context.
11. A more recent alternative involves a patch-based appraoch, which also operats on the output of convolution layers. Operating on patches in such a way gives the algorithm local understanding of the patterns in the image, which overall improves the precision of the style transfer since fewer errors are introduced by globally enforcing statistical distributions. Both gram-and patch-based approaches struggle to prvide reliable user controls to help address glitches. 
12. The primary parameter exposed is weighting factor between style and content; adjusting this results in either an abstract-styled mashup that mostly ignores the input content image, or the content appears clearly but its texture looks washed out. Finding a compromise where content is replicated precisely and the style is faithful remains a challenge-inparticular because the algorithm lacks semantic understanding of the input.
13. The information from the semantic map in m is used to compute the best matching patches and contributes to he loss value, but is not part the derrivative of the loss relative the current pixels. only the difference in activation x compared to the style patches cause an adjustment of the image itself via the L-BFGS algorithm.
14. The following experiments were generated from VGG19 network using augmented layers sem3_1 and sem4_1, with 3x3 patches and no additional rotated or scaled versions of the style images. The seed for the optimization was random, and rendering completed in multiple increasing resolutions-as usual for patch-based approaches. On a GTX 970 with 4GB of GPU RAM, rendering takes from 3 to 8 minutes depending on quality and resolution.
15. Transferring style in faces is arguably the most challenging task to meet expectations and particulary if the colors in the corresponding segments of the image are opposed.
16. Anonotations for nose and mouth are not required as the images are similar, however carefully annotating the eyeballs helps when generating photo-quality portraits.
17. Reducing the upredictability of neural networks certainly is a step forward making them more useful as a tool to enhance creativity and productivity.