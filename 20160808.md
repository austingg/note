2016-08-08
==========
# Handbook of Face Recoginition
1. A face recognition system generally consists of four moudles: detection, alignment, feature extraction, and matching, where localizatin and normalization(face detection and alignment) are processing steps before face recognition is performed.
2. Face detection segments the face ares from the background. In the case of video, the detected faces may need to be tracked using a face tracking component. Face alignment is aimed at achieving more accurate localization and at normalizing faces thereby whereas face detection provides coarse estimates of the location and scale of each deteced face. 
3. Facial components, such as eyes, nose, and mouth and facial outline, are located; based on the location points, the input face image is normalized with respect to geometrical properties, such as size and pose, using geometrical transforms or morphing. The face is ususally further normalized with respect to photometrical properties such illumination and gray scale.
4. A face image is efficiently represented as a feature vector of low dimensionality. The features in such subspace provide more salient and richer information for recognition than the raw image. The use of subspace modeling techniques has significantly advanced face recognition technology.
5. Face detection can be considered as a task of distinguishing between the face and nonface manifolds in the image (subwindow) space and face recognition between those of individuals in the face mainfold.
6. Face detection is the first step in automated face recognition. Its reliability has a major influence on the performance and usabiliity of the entire face recognition system.
7. With appearance-based methods, face detection is treated as a problem of classifying each scanned subwindow as one of two classes(i.e., face and nonface). Appearance-based methods avoid difficiulties in modeling 3D structures of faces by considering possible face appearances under various conditions. Building such a classifier is possible because pixels on a face are highly correlated, whereas those in a nonface subwindow present much less regularity.
8. AdaBoost is used to solve the following three fundamental problems: 
    * learning effective features from a large feature set
    * constructing weak classifiers, each of which is based on one of the selected features
    * boosting the weak classifiers to construct a strong classifier. 
   Weak classifiers are based on simple scalar  Haar wavelet-like features, which are steerable filter. Viola and Jones make use of several techniques for effective computation of a large number of such features under varying scale and location , which is important for real time performance.
   Moreover, the simple-to-complex cascade of classifiers makes the computation even more efficient, which follows the principles of pattern rejection, and coarse to find search.
9. A new boosting algorithm, called FloatBoost, is proposed to incorporate Floating Search into AdaBoost(RealBoost). The backtrack mechanism in the algorithm allows deletions of weak classifiers that are ineffective in terms of the error rate, leadinig a strong classifier consisting of only a small number of weak classifiers. 
10. Normalization of pixel intensity helps correct variations in imaging parameters in cameras as well as changes in illumination conditions. The meaning of resizing is apparent; intensity normalization operations, including mean value normalization, histogram equalization, and illumination correction.
11. In the case of discrete AdaBoost, the simplest type of weak classifiers is a "stump". A stump is a single-node decision tree. When the feature is real-valued, a stump may be constructed by thresholding the value of the selected feature at a certain threshold value; when the feature is discrete-valued, it may be obtained according to the discrete label of the feature. A more general decision tree (with more than one node) composed of several stumps leads to a more sophisticated weak classifier.
12.  The stump is determined by comparing the selected feature zk with a threshold Tk as follows.


# TODO
1. tzutalin / lableImg, play with it
2. warpaffine