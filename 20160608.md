2016-06-08
==========
### Linux Command
1. scp:  scp username@ip:/xxxxx xxx   secure file across server
2. skipping incompatible when link libc.so ....   32bit / 64bit
3. file /usr/local/libc.sof

### Brewing Deep Networs With Caffe
1. convert the data to Caffe-format, leveldb, hdf5/.mat, list of images LMDB
2. Write a Network Definition
3. Write a Solver Protobuffer
4. Train with the provide train_net tool 
  - build/tools/train_net.bin solver.prototxt


5. `Examples are your friends.`

6. finetune
  - input 
  - new fc layer. new layer name, new weight
  - num_output
  
### Cmake
1. find_package(Boost 1.46 REQUIRED COMPONENTS system thread filesystem regex)
2. find_package(OpenCV QUIET COMPONENTS core highgui imgproc imgcodecs videoio)

### Python & Numpy Tutorial
1. file operation ---- library shutil: copy, copyfile, move
2. Note that unlike many languages, Python does not haveunary increment or decrement operators. 
3. Python implements all of the usual operators for boolean logic, but uses English words rather than symbols( &&, ||). 
```
print type(t)
print t and f
print t or f
print not t
print t != f
```
4. String: hw12 = '%s %s %d' % (hello, world, 12) sprintf style string formatting.
5. String objects have a bunch of useful methods, upper, replace, strip


### [Building powerful image classifacation models using very little data](http://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)
1. In this tutorial, we will present a few simple yes effective methods that you can use to build a powerful image classifier, using only very few training examples -- just a few hundred or thousand pictures from each class you want to be able to recognize.
2. We will go over the following options:
  - training a small network from scratch (as a baseline)
  - using the bottleneck features of a pre-trained network
  - fine-tuning the top layers of a pre-trained network.
3. To acquire a few hundreds or thousands fo training imgaes belonging the classes you are interested in, on possibility would be to use the Flickr API to download picture matching a given tag, under a friendly license.
4. In our examples we will use two sets of pictures, which we got from Kaggle: 1000 cats and 1000 dogs (although the original dataset had 12,500 cats and 12,500 dogs, we just took the first 1000 images for each class)
5. A message that I hear often is that "deep learning is only relevant when you have a huge amount of data". While not entirely incorrect, this is somewhat misleading.

### Ubuntu Skill 

### Python numpy tutorial & codeacademy

### OpenCL-caffe wiki
instruction to create ImageNet 2012

### Deep Learning in a Nutshell: Core Concepts