Very thin and highly absorbent Xuan paper is commonly used to vividly pick up the sepcial charm of 
ink dispersion. To reduce absorbency, the paper can be treated with alum.


In the graphics community, the term 'ink diffusion' has been traditionally used to describe ink despersion in 
absorbent paper. However, in physics, 'diffusion' refers to the random walk of particles towards
the less concentrated regions. It is mathematically 
described by Fick's law. In effect, diffusion simply averages out any spatial difference in the concentration, making the concentration 
approach a constant with time. In reality, the actual process of ink dispersion is a complex interplay between paper, water, and ink constituents.

Ink dispersion can be viewed as a two-part process: the percolation of water and the movement of pigments within the water.
Water flows through the paper fibers in low speed due to water pressure and capillary attractions.

voids in the paper, alum, and the accumulation of ink constituents all may 
impede the flow, inducing momentum exchange. The dispersion of pigments in the water
is mainly caused by the spatial difference in the water velocity and the hindrance by paper fibers;
pigments diffusion only plays a minimal role.

To produce more realistic brush strokes, later research efforts incorporated physics into the brush models.
Unfortunately, all these models are too simplistic to produce the effects of some commonly used painting
techniques. For example, the cone model ignores the brush tip when a brush is pressed down, and thus fails to produce
slanted-brush is strokes(in which the tip travels along one side of stroke rather than staying in the middle)in painting
and calligraphy.

The coordinate system is controlled by the QPaitner class. Together with 
QPainterDevice and QPaintEngine classes, QPainter from the basis of Qt's
painting system, Arthur. QPainter is used to perform drawing operations, 
QPaintDevice is an abstraction of a two-dimensional space that can be painted
on using a QPainter, and QPaintEngine provides the interface that the painter
uses to draw onto different types of devices

The QPaintDevice class is the base class of objects that can be painted:
Its drawing capabilities are inherited by the QWidget, QPixmap, QPicture, QImage, and QPrinter classees.
The default coordinate system of a paint device has its origin at 
the top-left corner. The x values increase to the right and the y values increase downwards.
The default unit is one pixel on pixel-based devices and one points(1/72 of an inch)on printers.

The mapping of logical QPainter coordinates to the physical QPaintDevice coordinates are handled by QPainter's transformation matrix, viewport
and window. the logical and physical coordinate system coincide by default.


The RenderHint enum is used to specify flags to QPainter that may or may not be respected by
any given engine. The QPainter::Antialiasing value indicates that the engine should antialias eges of primitives if possible,
i.e. smoothing the edges by using different color intensities.


cv::Mat cv::getRotationMatrix2D(Point2f center, double angle, double scale)
{
	angle * = CV_PI/180;
	double alpha = cos(angle)*scale;
	double beta = sin(angle)*scale;
	
	Mat M(2, 3, CV_64F);
	double* m = (double*)M.data;
	
	m[0] = alpha;
	m[1] = beta;
	m[2] = (1-alpha)*center.x - beta*center.y;
	m[3] = -beta;
	m[4] = alpha;
	m[5] = beta*center.x + (1-alpha)*center.y;
	
	return M;
}


When performing image transformation and manipulation techniques, it is often necessary to employ some of interpolation or filtering
in order to obtain a good image quality. For example, if you scale an image, you can determine the final color of
each pixel by either some basic nearest neighbor method, or a more advanced interpolation method.
However, an interpolation method will invariably offer better final image quality.
In this tutorial, we will be writing a function to rotate an image, using bilinear interpolation.
The only problem is that there is no such thing as fractional pixels!
Instead of simply choosing the color of the nearest available pixel, we can get better results by intelligently averaging the colors of the four closest pixels.
This is called interpolation, and it is used after image transforms to provide smooth, accurate the visually appealing images.



We use five control points, P0 to P4, for the evaluation of the spline, whose coordinates in the radial-grayscale plane are as indicated.
We use a simple strategy, multi-pass diffusion model, to deal with this case.

However, the ratio of these two coefficients, not their individual values in the KM
model is important. Therefore, the scattering coefficient S was set to 1 and only the
absorption coefficient K was computed with the following equation.


A bilateral filter is a non-linear, edge-preserving and noise-reducing smoothing filter for images.

Creating Chinese ink paintings usually requires great skill, concentration, and years of training.

Sketch2Photo 有一个和腾讯一起做的商业化版本，项目主页上有链接。这个检索部分的核心方法是salient object detection and segmentation + Shape matching。都有开源代码：http://mmcheng.net/SalObj/ 和 Shape Context。合成部分用开源的matting代码应该不会太差。

YUV formats fall into two distinct groups, the packed formats where Y, U(Cb), and V(Cr) samples are packed together into macropixels which are stored in s single array, and the plannar formats where each component is stored as a separate array, the final image being a fusing of the three separate planes.

in the diagrams below, the numerical suffix attached to each Y, U, or V sample indicates the sampling position across the image line, so, for example, V0 indicated the leftmost V sample and Yn indicates the Y sample at the (n+1)th pixel from the left.

Subsampling intervals in the horizontal and vertical directions my merit some explanation. The horizontal subsampling interval describes how frequently across a line a sample of that component is take while the vertical interval describes on which lines samples are taken.
For example, UYVY format has a horizontal subsampling period of 2 for both the U and V components indicating that 
U and V samples are taken for every second pixel across a line.
Their vertical subsampling period is 1 indicating that U and V samples are taken on each line of the image.

YUV is a color space typically used as part of a color image pipeline. It encodes a color image or video taking human perception into account, alowing reduced bandwidth for
chrominance components, thereby typically enabling transmission errors or compression artifacts to be more efficiently masked by the human perception than using a direct RGB-representation. Other color spaces have similar properties, and the main reason to implement or investigate
properties of YUV would be for interfacing with analog or digital television or photographic equipment that conforms to certain YUV standards.

The scope of the terms YUV, Y'UV, YCrCb, YPbPr, etc., is sometimes ambiguous and overlapping. Historically, the terms
YUV and Y'UV were used for specific analog encoding of color information in television systems, while YCbCr was used for digital encoding of color information suited for video and still-image compression and transmission such as MPEG and JPEG. Today, the term YUV is commonly used in the computer industry to describe file-formats that are encoded using YCbCr.

YPbPr color model used in analog component videoo
and its digital version YCbCr used in digital video 	
are more or less derived from it.


An adaptive real-time skin detector based on Hue thresholding : A comparsion on two motion tracking methods.

在不增加绘制物体几何复杂度的情况下，此阿勇纹理作用可以有效的表现景物表面的细节特征，增加绘制场景的真实感。


The Photoshop brush engine allows you to create your own brushes, starting from a brush tip shape that can be just
a circle or a sampled image. This shape is repeated along the stroke. To avoid this looking boring, Photoshop gives you
some tools to vary these shapes along the line to get a more complex look. Especially when working with a pressure
sensitive stylus there are great ways to get a natural feel
to your brushwork.

The brush engine of photoshop is based on brush marks. These brush marks can have different shapes. They can just be circles or sampled monochrome images, where the black parts are the parts with the most opacity.

If you draw a line either with your digitizing tablet or just with a mouse, there will be drawn brush marks along
this line at an certain spacing interval.

Shape-Dynamics, Scattering, Texture, Dual Brush, Color Dynamics and other dynamics offer you the tools to modify
the way these marks are drawn on the canvas.


if you choose a control, your graphics pad doesn't support, there will be an exclamation point left of the drop-down menu warning you.

This is where you really start to set up your own brush. This can be a simple circle, a square or a more natural shape by using s sampled image.

Diameter is just the basic size of your brush that later be changed as always.

Roundness compresses the shape of you brush by specifies the ratio between the brush's short and long axes. If you are using a round brush it gives you an ellipse. For any other brush it just makes it smaller in on axes.

hardness can only be used for the standard round or elliptic brush, not for sampled brushes. Decreasing the hardness will
blur the edges of the circle, giving your a softer brush.

spacing is a good way to see how the brush engine of photoshop works. Increase the spacing and the single brush marks will be drawn apart. The smaller the spacing, the more the brush marks will overlap each other. if you are just working with a round brush it is the best to decrease the spacing but when working with a textured brush this could probably cause a overlapping of the texture. if you are having performance issues you can also try to increase the spacing. Deactivating spacing will make the space between the single brush marks depend on how fast you move the brush.



Shape dynamics

The size jitter is one of the most common jitters, especially when used with pen pressure. it specifies how the size of brush marks vary in a stroke.

The angle jitter allows you to determine the angle of the brush marks.

The roundness jitter works the same way as the roundness from the brush tip shape menu, just that it lets you vary it.

Scattering
with the scatter the position of your brush tip is randomized around its original position. If both Axis is enabled very single brush mark will be randomly scattered around a certain radius depending on the scatter. If both axis is disabled it will only scatter in the right angle from your line. If you choose a control for scatter you must set it higher than 0%, otherwise it won't do anything.

where d represents the direction perpendicular to the stroke orientation. d = O - pi/2;


The mark-making techniques used in these commercial programs are not published but as far as I can tell, all of them are 2D stamp or sweep based.



Acylic graph for input/output mapping


this will require some developer manpower, and a lot of testing, but should hopefully be unenventful for end-user.


****************************************************

This opens the main Brushes panel, the big brother of the Brush Preset picker we saw earlier. To select a brush, simply click on its icon. Scroll down the list to your newly created brush and click on its icon to select it if it's not selected already.

In the real world, if you were to paint with an actual brush, the brush would lay down a continuous coat of paint on the paper, but that's not how photoshop works.
Instead, Photoshop "stamps" the document with your brush tip as you drag your mouse. If the stamps appera close enough together, it creates the illusion of a seamless brush stroke, but if the stamps are spaced to far apart form each other, the individual stamp become obvious and the stroke appear ridged. But in most cases, a seamless brush stroke is more desirable.


*******************************************************
OpenGL pipeline blending

When blending is active, the input colors from the fragments processor does not merely overwrite the corresponding value currently in the output buffer, but 
instead combined together based on a function.

The fragment shader can write a number of colors. These colors are mapped to particular images in the framebuffer via glDrawBuffers. Blending happens independently on each fragment shader output value.

Blending must be enabled with a call glEnablei(GL_BLEND, i), where i is an integer representing the buffer to enable blending on. Each buffer being written to by a fragment shader can hava blending separately enabled disabled.

When blending is disabled to a buffer, the color from the fragment shader will directly be written to that buffer.

When computing the output color, two equations are used. one for the RGB portion of the output color, and one for the alpha of the output color. This is useful is you want to do something like blending the source and dest colors but take the source alpha as the fragment out produced it.

The two equations are set with this function:
void glBlendEquationSeparate(GLenum modeRGB, GLnum modeAlpha)

The possible equations are as follows:
GL_FUNC_ADD: The source and destination colors are added to eacheother.
The s and d blending parameters are multiplied into each of S and D before addtition.
GL_FUNC_SUBTRACT: subtracts the destination from the source.
GL_FUNC_REVERSE_SUBTRACT: subtracts the source form the destination.

GL_MIN、GL_MAX


The traditional alpha blend is set up as follows;

glBlendEquationSeparate(GL_FUNC_ADD, GL_FUNC_ADD);
glBlendFuncSeparate(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA, GL_ONE, GL_ZERO);