2016-03-14
===============
### Facebook/fb-caffe-exts
[link](https://github.com/facebook/fb-caffe-exts)

Some handy utility libraries and tools for the Caffe deep learning framework.
fb-caffe-exts is a collection of extensions developed at FB while using Caffe in (mainly) production scenarios.

#### predictor/
* A simple C++ library that wraps the common pattern of running a caffe::Net in multiple threads while sharing weights. It also provides slightly more convenient usage API for the inference case.
* Of note is the predictor/Optimize, which optimizes memory usage by automatically reusing the intermediate activations when this is safe. This is reduces the amount of memory required for intermediate activations by around 50% for AlexNet-style models, and around 75% for GoogleNet-style models.
* Depending on the model, the buffer reuse can also lead to some non-trivial performance improvments at inference time. To enable this just pass Predictor:Optimization::MEMORY to the Predictor.

#### torch2caffe
A library for converting pre-trained Torch models to the equivalent Caffe models.

#### conversions
A simple CLI tool for running some simple caffe network transfromations.
The main usage at the moment is automating the Net Surgery notebook.


### OptNet - reducing memory usage in torch neural networks

Memory optimization for torch neural network
Heavily inspired from the Optimizer from https://github.com/facebook/fb-caffe-exts

It goes over the network and verify which buffers can be reused. Currently, it only supports evaluation mode, but training model will soon be included.



1. Compress model and speeding up. 
    * SqueezeNet 
    * Rethinking, bottleneck
    * memory saving method. At least can improve throughout ratio at tesing time. if there are many many image to process. 
    * MXNet: Computation graph -> in-place and memory reuse.
2. Common neural network architecture
3. Net2Net and NetMorphism
4. Object detection
5. Visualization and understanding
6. Image Retrival
7. Semantic Segmentation
8. familiar with famous Deep Learning Framework.


### You Only Look Once: unified, real-time object detection

* Prior work on object detection repurposes classifier to perform detection. Instead, we frame object detection as a regression problem to spatially bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probailities directly from full images in one evaluation.
* Our unified architecture is also extremely fastl YOLO processes images in real-time at 45 frames per second, hundreds to thousands of times faster than existing detection systems.
* Current detection systems repurpose classifiers to perform detection. To detect an object these systems take a classifier for that object and evaluate it at variouss locations and scales in a test image. The classifer then takes additional time to evaluate the proposals. The best performing systems require 2-40s per image even those opimized for speed do not achieve real-time performance.
* Our system is refreshingly simple. A single convolutional network simultaneously predicts multiple bounding boxes and class probabilities for those boxes.
* Using our system, you only look once at an image to predict what objects are present and where they are. Our network uses features from the entire image to predict each bounding box. This means our network reason globally about the full iamge and all the objects the image.
* ImageNet 224x224 -> enlarge 448x448 input. Our system models detection as a regression problem to a 7x7x24 tensor. This tensor encodes bounding boxes and class probabilities for all objects in the image.
    1. 224x224 -> 448x448 -> 7x7 grid cell   24(20 class prob + 4 bounding box)
    2. 24 convolutional layers (20 + 4) + 2 FC
    3. Alternating 1x1 convolutional layers reduce the features space
    4. pretrain the convolutional layers on the ImageNet classification task at half resolution and then double the resolution for detection.
    5. use strided convolutional layers to downsample the feature space instead of maxpooling layers.
    6. Our network architecture is inspired by the GoogleNet model for image classification. Instead of the inception modules used by GoogleNet we simply use 1x1 reduction layers followed by 3x3 convolutional layers. We also replace maxpooling layers with strided convolutions.
    7. pretrain 20 conv layers with top5 acc 86% on ImageNet 2012.