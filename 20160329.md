2016-03-29
===============
```C++
BlobProto meanProto;
ReadProtoFromBinaryFileOrDie("style_mean.binaryproto", &mean_proto);

Blob<float> meanblob;
meanblob.FromProto(meanProto);


caffe_gpu_memcpy();

Net.blobs();
Net.layers();
Net.layer_names();
Net.learnable_params();

Blob.shape_string();
```

### Neural Network and Deep learning
1. Neural Network: a beautiful biologically-inspired programming paradigm which enables a computer to learn from observational data.
2. Deep learning:  a powerful set of techniques for deep learning in neural networks.


* **The unstatble gradient problem**: The fundamental problem isn't so much the vanishing gradient problem or the exploding gradient problem. It's that the gradietn in early layers is the product of terms from all the later layers. When there are many layers, that's an intrinsically unstable situation.

* The only way all layers can learn at close to the same speed is if all those products of terms come close to balancing to occur.

* In short, the real problem here is that neural networks suffer from an unstable gradient problem. As a result, if we use standard gradient-based learning techniques, different layers in the network will tend to lear at wildly different speeds.
* This slowdown isn't merely an accident or inconvenience: it's fundamental consequence of the approach we're taking to learning.
* Earlier hidden layers are learning much slower than later hidden layers. early layers learn slower than later layers.





### vocabulary
siamease
intrinsic
