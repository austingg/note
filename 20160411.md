2016-04-11
========
# Introduction to debugging neural networks
1. From reddit: 
    * The question of where in the network to use dropout is also sill open(everywhere or only in the fully connected layers?).
    * The idea of starting with a small subset of dataset to ensure you can overfit is great. There is another dimension to this though, which not mentioned here: I think you should also start with a small model (few layers with few units), so you can iterate fast and try out more different ideas. Many people seem to have the reflex to throw a 100M+ parameter at every new problem, but that's just going to slow down from the start. Scaling up the model is fairly easy, tuning the model architecture for the task at hand is not.
2. Orignial Notes:
    * Neural nets are fundamentally harder to debug than most programs, because most neural net bugs don't result in type errors or runtime errors. They just cause poor convergence. Especially when you're new, this can be very frustrating.
    * But an experienced neural net trainer will be able to systematically overcome the difficulty in spite of the ubiquitous and seemingly ambiguous error message: Performance Error: your neural net did not train well. to the uninitated, the message is daunting. But to the experienced, this is a great error.
3. How to deal with NaNs: By far the most common first question I get from student is, "Why am I getting NaNs." Occasionally, this is a complicated answer. 
    * But most often, the NaNs come in the first 100 iterations, and the answer is simple: your learning rate is too high. reducing the learning rate by a factor of 3 until you no longer get NaNs in the first 100 iterations.
    * If you are getting NaNs beyond the first 100 iterations, there are 2 further common causes. 1)If you are using RNN, make sure that you are using gradient clipping.
    * If you have written any custom layers yourself, there is a good chance your own custom layer is causing the problem in a division by zeros scenario. Another notoriously NaN producing layer is the softmax layer. The softmax computation involves an exp(x) term in both the numerator and denominator, which can divide Inf by Inf and produce NaNs. Make sure you are using statilized softmax implementation.
 4. What to do when your nerual net isn't learning anything
    * 
    
    
### CUBLAS_STATUS_MAPPING_ERROR 
* means the copy from the device to the host failed. CUBLAS functions are usually wrappers around one or several kernel lauches. Kernels lauches are asynchronous, and errors occuring during kernel exectution are thus reported on the next synchronous operation, which ofter is a cuaMemcpy() or cudaMemcpy2D which is what cublasGetMatrix() maps to.
* Given your hardware, I think the DGEMM kernel may be triggering the operating system watchdog timer, which then kills the kernel, causing the subsequent copy to fail. You can check into the execution time of the kernels with the CUDA profiler if you see it approaching 2 seconds or so before it fails, that would be a good indication that my hypothesis is correct. The watchdog timer is there for the purpose of keeping the GUI responsive. Running Without a GUI will allow your app to occupy the GPu with a compute kernel for as long as it pleases.
* Here is what you would see for the case of an out-of-memory condition: cudaErrorMemoryAllocation
* Based on prior expeience with CUBLAS_STATUS_MAPPING_EEROR in apps using CUBLAS, the next hypothesis is that the GEMM kernel is killed by the watchdog timer. Since this is an asynchronous event, it would cause the next synchronous CUDA API call to report the error, in your code, that would be the CUDA API calls inside cublasGetMatrix(). The watchdog timer is a feature of all operating systems supported by CUDA whose purpose is th ensure that the GUI does not freeze up for extended periods of time. Since the GPu can, at any given time, either service the GUI, or run a CUDA kernel, lengthy CUDA kernels can block graphics, causing the watchdog timer to trigger. The time limit is in the 2-5 second range if I recall correctly.
* The watchdog timer is enabled whenver your machine is running with a GUI, regardless of whether your app uses the GUI.

