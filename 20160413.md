2016-04-13
========
# ImageRetrieval
### Neural Codes for Image Retrieval - ECCV2014
1. It has been shown that the activations invoked by an image within the top layers of a large convolutional neural network provide a high-level descriptor of the visual content of the image.
2. we found that neural codes perform competitively even when the convoltional neural network has been trained for unrelated classification task. 
3. We further evaluate the performance fot e compressed neural codes and show that a simple PCA compression provides every good short codes that give state-of-the-art accuracy on a number of datasets. 
4. Finetune may get a high performance on the training data but degrade on other dataset compared with the original network.
5. We evaluate the performance of the PCA compression and observer that neural codes can be compressed very substantially, e.g. to 128 dimensions, with virtually no loss of the retrieval accuracy.
6. Benchmar datasets:
    * Oxford Buildings datasets 5062 images  11 landmarks
    * INRIA Holidays datasets: 1491 vacation images corrsponding to 500 groups based on same scene or object.
    * University of Kentucky Benchmark dataset: 10200 indoor photographs of 2550 objects.
7. Several conclusions and observations that onc can draw from our experiments:
    * Neural code perform well, even when one uses the CNN trained for the classification task and when the traning dataset and the retrieval dataset are quite different from each other. Unsurprisingly, this performance can be further improved, when the CNN is retrained on photographs that are more related to the retrieval dataset.
    * room for improvements: higher resolution.
    * the best performance is observed not on the very top of the network, but rather at the layer that is two levels below the outputs. This is because the very top layers are too much tuned for the classification task.
    
 ### Aggreagating Deep **Convolutional Features** for Image retrieval ---- ICCV2015
 1. begin to use the convolution feature map not only the fully-connected layers.
 2.
 
 ### Deep Leaning of **Binary Hash Codes** for **Fast** Image Retrieval
 1. Approximate nearest neighbor search is an efficient strategy for large-scale image retrieval.
 2. We propose an effective deep learning framework to generate binary hash codes for fast image retrieval. Our idea is that when the data labels are avaliable, binary codes can be learned by employing a hidden layer for representing the latent conceptis that dominate the class labels.
 3. Content-based image retrieval aims at searning for similar images through the analysis of image content; hence image representations and similarity measure become critical to such a task.
 4. Along this research track, one of the most challenging issues is associating the pixel-level information to the semantics from human perception. Despite several hand-crafted features have been proposed to reprensent the images, the performance of these visuall descriptors is still limited until the recent breakthrough of deep learning. Recent studies have shown that deep CNN significantly improves the performance on various vision tasks, such as object detection, image classification, and segmentation. These accomplishments are attributed to the ability of deep CNN to learn the rich mid-level image representations.
 5. However, because the CNN features are high-dimensional and directly computing the similarity between two 4096-dimensional vectors is inefficent.  Babenko, proposed to compress the CNN features using PCA and discriminative dimensionality reductin, and obtained a good performance. 
 6. In CBIR, both image representations and computational cost play an essential role. Due to the recent growth of visual contents, rapid search in a large database becomes an emerging need. Many studies aim at answering the question that how to efficiently retrieve the relevant data from the large-scale database. Due to high-computational cost, traditional linear search (or exhaustive search) is not appropriate for searching in a large corpus. Instead of linear search, a practical stragegy is to use the techniques of Approximate Nearset Neightbor (ANN) or hashing based method for speedup.
 7. Benifiting from the produced binary codes, fast image search can be carried out via binary pattern matching Hamming distance measurement, which dramatically reduces the computational cost and further optimizes the efficiency of the search.  
 8. With small modifications of the network model, our deep CNN simultaneously learning domain specific image representations and a set of hashing-like functions for rapid image retrieval.
 9. We use pre-trained CNN model propsed by Alex from the Caffe CNN library, which is trained on large-scale imageNet dataset which containes more than 1.2 million images categorized into 1000 object classes. 
 10. We assume that the final outputs of the classification layer F8 rely on a set of h hidden attributes with each attribute on or off. In other points of view, images inducing simlar binary activations would have the same label. To fufill this idea, we embed the latent layer H between F7 and F8. The laten layer H is a fully connected layer, and its neuron activities are regulated by the succeeding layer F8 that encodes semantics and achieves classification. the proposed latent layer H not only provides an abstraction of the rich features from F7, but also bridges the mid-level features and the high-level semantics. In our design, the neurons in the layer H are activated by sigmoid  functions so the activations are approximated to {0, 1}.
 11. Supervised semantic-preseving deep hashing
 12. Benchmark dataset:
    * Yahoo-1M dataset: contains a total of 1,124,087 shopping product images, categorized into 116 clothing-specific classes.
    * SUN 
 
 ### Training Region-based Object Detectors with Online Hard Example mining
 1. RCNN series' training procedure still includes many heuristics and hyperparameters that are costly to tune. we present a simple yet surprisingly effective online hard example mniing (OHEM) algorithm for training region-based ConvNet detectors. Our motivation is the same as it has always been - detection datasets contain an overwhelming number of easy examples and s small number of hard examples. Automatic selection of these hard examples can make training more effective and efficient.
 2. OHEM is a simle and intuitive algorithm that eliminates several heuristics and hyperparameters in common use. But more importantly, it yields consistent and significant boosts in detection performance on benchmarks.
 3. Object detectors are often trained through a reduction that converts object into an image classification problem. This reduction introduces a new challenge that is not found in natrual image classification tasks: the training set is distinguished by a large imbalance between the neumber of annotated objects and the number of background examples.
 4. bootstrapping: the key idea was to gradully grow, or bootstrap, the set of background examples by selecting those examples for which the detector triggers a false alarm. this strategy leads to an iterative training algorithm that alternates between updating the detection model given the current set of examples, and then using the updated model to find new false positives to add to the bootstrapped training set.
 5. It may seem odd then that the current  state-of-the-art object detectors, embodied by Fast R-CNN and its descendants, do not use bootstrapping. The underlying reason is a technical difficulty brought on by the shift towards purely online learning algorithms, particularly in the context of deep ConvNets trained with stochastic gradient descent(SGD) on millions of examples. Training deep ConvNet detectors with SGD typically requires hundreds of thousands of SGD steps and freezing the model for even a few iterations at a time would dramatically slow progress. What is needed, instead, is a purely online form of hard example selection.
 6. The idea of dataset bootstrapping, typically called hard negative mining in recent work appears in the training of moset successful object detector.
 7. The FRCN network itself can be divided into two sequential parts: a convolutional (conv) network with several convolution and max-pooling layer, and an RoI network with an RoI-pooling layer, several fully-connected (fc) layers and two loss layers. 
    * Convolutional Network
    * RoI Network
    for each object proposal, the RoI-pooling layer projects the proposal onto the conv feature map and extracts a fixed-length feature vector.
 8. To share conv network computation between RoIs, SGD mini-batches are created hierarchically. For each mini-batch, N images are first sampled from the dataset, and then B/N RoIs are sampled from each image. Setting N = 2 and B = 128 works well in practice.
    * Foreground RoIs: IoU with ground-truth bounding box >= 0.5
    * Background RoIs. IoU with ground-truth [bg_lo, 0.5), a lower threshold of bg_lo = 0.1 is used by both FRCN and SPPnet ares hypothesized in to crudely approximate hard negative mining; the assumption is taht regions with some overlap with the ground truth are more likely to be the confusing or hard ones.
    * Balancing fg-bg RoIs: rebalance the foreground-to-background ratio in each mini-batch to target of 1:3 by undersampling the background patches at random.
9. Although this heuristic helps convergence and detection accuracy, it is suboptimal because it ignores some infrequent, but important, difficult background regions. 
10. Main Contributions:
    * faster training
    * remove bg_lo
    * remove resampling bg patches.
 11. Our main observation is that these alternating steps can be combined with how FRCN is trained using online SGD. The key is that although each SGD iteration samples only a small number of images, each image contains thousands of example RoIs from which we can select the hard examples rather than a heuristically sampled subset.
 12. The online hard example mining algorithm (OHEM) proceeds as follows. 
    * compute a conv feature map suing the conv network
    * RoI network uses this feature map and the all inpute RoIs, to do a forward pass.
    * use standard non-maximum suppression to perform deduplication.
    * Hard examples are selected by sorting the input RoIs by loss and taking the B/N examples for which the current network performs worst. 
    * use the hard example to do backward and upate
 13. Implementation Details:
    * straightforward or naive way, set the non-hard RoIs to 0. backward all RoI network
    * readonly RoI network select  hard examples, which are input to the regular RoI network. only B RoI need to do backward.
 ### Hamming distance in C/C++
 1. xnor and count 1s. (when descriptor is short than 64 integer)
 2. std::bitset<N>, defined in the <bitset> header, whereN is the number of bits. compute the Hamming distance between two binary codes a and b using (a ^ b).count().
 
 
 ### Miscellaneous
 1. t-SNE visualize the descriptor for better understanding
 2. consuming code: code that relies on many APIS, libraries and other helper is high-level.
 3. Design patterns represent a wealth of collective knowledge and experience. The proper use of these patterns will help to ensure that systems are malleable, enbaleing rapid change. Creational patterns describe object-creation mechanisms that enable greater levels of reuse in evolving systems. Rather than creating the product instance directly, the client delegates this responsibility to the factory. The factory completely abstracts the creation and initialization of the product from the client. This indirection enables the client to focus on its discreate role in the application without concerning itself with the details of how the product is created. Thus as the product implementation changes over time, the client remains unchanged.